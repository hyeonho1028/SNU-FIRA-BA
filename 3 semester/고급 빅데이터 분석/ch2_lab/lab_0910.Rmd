---
title: "Lab_0910"
author: "Hyeonho Lee"
date: "2018년 9월 10일"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F,warning=F)
```


```{r}
cereals = read.csv('C:/workspace/Github/snu_edu/3 semester/고급 빅데이터 분석/ch2_lab/cereals.csv')
cereals
```

```{r}
cereals = cereals[, c("name","calories","protein","fat","sodium","fiber","carbo","sugars","potass","vitamins")]
dim(cereals)
```

```{r}
## missing value가 있는 자료는 삭제
cereals[!complete.cases(cereals),] #na.omit(cereals)
cereals = cereals[complete.cases(cereals),]
dim(cereals)
length(which(is.na(cereals)))
```


```{r}
rownames(cereals) = cereals[,"name"]
cereals = cereals[,-1]
head(cereals,6)

```


#---- 2-2. 계층적 군집분석(p.60)

## 산포도 확인
```{r}
plot(cereals)

```

##- 계층적 군집분석

# 거리 측도 : 유클리디안, Minkowski, Maximum
# Linkage : single, complete, centroid, average
```{r}
#k1=3
dist.E =dist(cereals)
```



# (1) Euclidean dist., complete <- default option
```{r}
cluster.EC = hclust(dist.E) 
plot(cluster.EC, main="Euclidean, complete", cex=1, pty = 'm')



library(ggplot2)
ggplot(cluster.EC) + geom()

# load package ape; remember to install it: install.packages('ape')
library(ape)
# plot basic tree
plot(as.phylo(cluster.EC), cex = 0.5, label.offset = 1)

```

# (2) Euclidean dist., single linkage
```{r}
cluster.ES = hclust(dist.E, method="single")
plot(cluster.ES, main="Euclidean, single")
```



# (3) Euclidean dist., average linkage
```{r}
cluster.EA = hclust(dist.E, method="average")
plot(cluster.EA, main="Euclidean, average")
```




## 군집 분할(할당)
```{r}
clusters = cutree(cluster.EC, k=2:6) #군집 수 조절
head(clusters)
clusters = cutree(cluster.EC, h=100) #덴드로그램의 높이 조절
clusters[1:10]
```


# 덴드로그램에서 할당
```{r}
plot(cluster.EC, main="Euclidean, complete")
groups = cutree(cluster.EC, h=100)
head(groups,20)
rect.hclust(cluster.EC, h=100, border="red")

plot(cluster.EC, main="Euclidean, complete")
groups = cutree(cluster.EC, k=4) 
head(groups,20)
rect.hclust(cluster.EC, k=4, border="red") # draw denrogram with red borders around the k1 clusters
```



## 군집 내 비교 (k=4) using Euclidean dist. and complete linkage
```{r}
for (i in 1:4){
  cat(i,'- th cluster \n')
  tmp = rbind(round(colMeans(cereals[which(groups==i),]), 3),
              round(diag(cov(cereals[which(groups==i),])), 3)); rownames(tmp) = c("Mean","Var")
  print(tmp)
}
table(groups)
```




# linkage 에 따른 군집할당 결과 비교
```{r}
Clu.Ave = cutree(cluster.EA, k=4)
Clu.Sig = cutree(cluster.ES, k=4)
Clu.Com = cutree(cluster.EC, k=4)

table(Clu.Ave, Clu.Sig)
table(Clu.Ave, Clu.Com)
table(Clu.Sig, Clu.Com)
```





#--- 2-3. K-means 군집분석(p.73)
```{r}
# K-means 결과
library(cluster)
cluster.K4 = kmeans(cereals, centers=4)
cluster.K4

plot(cereals, col=cluster.K4$cluster) #k-means
```





# 초기값에 따른 군집분석의 차이
```{r}
set.seed(1)
cluster1= kmeans(cereals, centers=4)
set.seed(2)
cluster2= kmeans(cereals, centers=4)

table(cluster1$cluster, cluster2$cluster)
cluster1$centers
cluster2$centers
```




## 군집 수 K 정하기
```{r}
wss <- vector(length=15)
for (i in 1:15) wss[i] = kmeans(cereals,centers=i, nstart = 10)$tot.withinss
plot(1:15, wss, type="b", xlab="Number of Clusters",
     ylab="Within groups sum of squares",
     main = "Total within SS for varying K") 
```






#--- 2-1. 다차원 척도분석(p.10)
```{r}
cmds = cmdscale(dist.E, k = 2)
head(cmds)
plot(cmds, xlab = "coord 1", ylab = "coord 2", main = "MDS", type = "n")
text(cmds, labels = rownames(cmds), cex=.8)
```





#--- 다차원 척도법을 이용한 군집분석 시각화(p.81)
```{r}
k1 = 4

groups = cutree(cluster.EC, k=k1)
plot(cmds, xlab = "coord 1", ylab = "coord 2", main = "MDS", type = "n")
text(cmds, labels = rownames(cmds), cex=.8, col=groups)

groups = cutree(cluster.ES, k=k1)
plot(cmds, xlab = "coord 1", ylab = "coord 2", main = "MDS", type = "n")
text(cmds, labels = rownames(cmds), cex=.8, col=groups)

groups = cutree(cluster.EA, k=k1)
plot(cmds, xlab = "coord 1", ylab = "coord 2", main = "MDS", type = "n")
text(cmds, labels = rownames(cmds), cex=.8, col=groups)

plot(cmds, xlab = "coord 1", ylab = "coord 2", main = "MDS", type = "n")
text(cmds, labels = rownames(cmds), cex=.8, col=cluster.K4$cluster)
```






#--- PCA 를 이용한 군집분석 시각화(p.78)
# PCA : 차원 축소 방법중 하나. 자료의 분산을 고유값 분해
```{r}
pca <- princomp(cereals, cor=T)

groups = cutree(cluster.EC, k=k1)
plot(pca$scores[,1:2], xlab = "coord 1", ylab = "coord 2", main = "PCA", type = "n")
text(pca$scores[,1:2], labels = rownames(pca$scores), cex=.8, col=groups)

groups = cutree(cluster.ES, k=k1)
plot(pca$scores[,1:2], xlab = "coord 1", ylab = "coord 2", main = "PCA", type = "n")
text(pca$scores[,1:2], labels = rownames(pca$scores), cex=.8, col=groups)

groups = cutree(cluster.EA, k=k1)
plot(pca$scores[,1:2], xlab = "coord 1", ylab = "coord 2", main = "PCA", type = "n")
text(pca$scores[,1:2], labels = rownames(pca$scores), cex=.8, col=groups)

plot(pca$scores[,1:2], xlab = "coord 1", ylab = "coord 2", main = "PCA", type = "n")
text(pca$scores[,1:2], labels = rownames(pca$scores), cex=.8, col=cluster.K4$cluster)
```