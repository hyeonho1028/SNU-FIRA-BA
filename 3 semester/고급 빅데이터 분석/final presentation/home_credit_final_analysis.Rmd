---
title: "home_credit_final_analysis"
author: "Hyeonho Lee"
date: "2018년 10월 18일"
output: html_document
---

```{r}
library(tidyverse)
library(caret)
# library(lightgbm)
library(knitr)
library(xgboost)
library(ggplot2)
library(magrittr)
```

```{r}
application_train = read_csv('D:/application_train.csv')
```

```{r}
ind = sample(nrow(application_train), nrow(application_train)*0.1, replace = F)

application_test = application_train[ind,]
application_train = application_train[-ind,]

y_test = application_test$TARGET
application_test$TARGET = NULL
```


```{r}
application_train2 <- application_train %>%
  select(-TARGET)

features <- colnames(application_train2)

for (f in features) {
  if ((class(application_train2[[f]])=="factor") || (class(application_train2[[f]])=="character")) {
    levels <- unique(application_train2[[f]])
    application_train2[[f]] <- as.numeric(factor(application_train2[[f]], levels=levels))
  }
}

application_train2$TARGET = NULL
application_train2$TARGET = as.factor(application_train$TARGET)
levels(application_train2$TARGET) = make.names(unique(application_train2$TARGET))


application_test2 = application_test 

features <- colnames(application_test2)

for (f in features) {
  if ((class(application_test2[[f]])=="factor") || (class(application_test2[[f]])=="character")) {
    levels <- unique(application_test2[[f]])
    application_test2[[f]] <- as.numeric(factor(application_test2[[f]], levels=levels))
  }
}
```

```{r}
formula = TARGET ~ .

fitControl <- trainControl(method="none",number = 5,  classProbs = TRUE, summaryFunction = twoClassSummary)

xgbGrid <- expand.grid(nrounds = 100,
                       max_depth = 7,
                       eta = .05,
                       gamma = 0,
                       colsample_bytree = .8,
                       min_child_weight = 1,
                       subsample = 1)

set.seed(13)

XGBModel = train(formula, data = application_train2,
                        method = "xgbTree",trControl = fitControl,
                        tuneGrid = xgbGrid,na.action = na.pass,metric="ROC"
                       )
# XGBModel
predictions = predict(XGBModel,application_test2,na.action=na.pass,type="prob")
```

```{r}
# AUC
library(ROCR)
# Training set
AUC = performance(prediction(predictions$X0, y_test) , "auc")
AUC@y.values # area under the curve

# ROC curve
ROC = performance(prediction(predictions$X0 ,y_test) , "tpr","fpr")
plot(ROC , main = paste("ROC curve for Train data\n AUC:",
round(as.numeric(AUC@y.values),4)),
col = "blue", lwd = 2.5)
abline(c(0,0), c(1,1), lty = 2, lwd = 2)
```

```{r}
importance = varImp(XGBModel)

varImportance <- data.frame(Variables = row.names(importance[[1]]), 
                            Importance = round(importance[[1]]$Overall,2))

# Create a rank variable based on importance
rankImportance <- varImportance %>%
  mutate(Rank = paste0('#',dense_rank(desc(Importance)))) %>%
  head(10)

rankImportancefull = rankImportance

ggplot(rankImportance, aes(x = reorder(Variables, Importance), 
                           y = Importance)) +
  geom_bar(stat='identity',colour="white", fill = "skyblue") +
  geom_text(aes(x = Variables, y = 1, label = Rank),
            hjust=0, vjust=.5, size = 4, colour = 'black',
            fontface = 'bold') +
  labs(x = 'Variables', title = 'Relative Variable Importance') +
  coord_flip() + 
  theme_bw()
```







Missing data exploratory
```{r}
data.table::data.table(
  missing = sapply(application, function(x) { (sum(is.na(x)) / length(x)) }),
  column = names(application)
  ) %>% filter(missing>0) %>% 
  ggplot(aes(x = reorder(column, -missing), y = missing)) + 
  geom_bar(stat = 'identity', fill = 'steelblue') + 
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(
    title='Missing data by feature',
    x='Feature',
    y='% missing') + 
  coord_flip()
```

```{r}
# 전체 NA
sum(is.na(application))/(nrow(application)*ncol(application)) 


count_target<-data.table::data.table(value = c("NA", "NOT NA"), count = c(9152465,37516342))
colors <- c('rgb(211,94,96)', 'rgb(114,147,203)')#, 'rgb(144,103,167)', 'rgb(171,104,87)', 'rgb(114,147,203)')

count_target %>% 
  plot_ly(labels = ~value, values = ~count) %>%
  add_pie(hole = 0.6) %>%
  layout(title = "Percent of NA",  showlegend = T,
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
```


----------------------------------------------------------------------------------------------------------------------------------------------

read in data
```{r}
application = read_csv('D:/application_train.csv')
application %<>% select(-c(EXT_SOURCE_1,EXT_SOURCE_2,EXT_SOURCE_3))
```

```{r}
missing_data_train <- as.data.frame(sort(sapply(application, function(x) sum(is.na(x))),decreasing = T))                                                   
colnames(missing_data_train)[1] <- "Missing_values"
missing_data_train$Percentage <- (missing_data_train$Missing_values/nrow(train))*100      
missing_data_train$Variables <- rownames(missing_data_train)
                                                
#Variables containing NAs less than 15% train dataset                                           
missing_data_train<-subset(missing_data_train,missing_data_train$Percentage<15)                                           
less_na_columns_train<-missing_data_train$Variables                                               

application %<>% select(less_na_columns_train)
```

```{r}
set.seed(123)
ind = sample(nrow(application), nrow(application)*0.9, replace = F)
train = application[ind,]
test = application[-ind,]

y_test = test$TARGET
test$TARGET = NULL
```

```{r}
full <- bind_rows(train,test)

Target <- train$TARGET
Id <- test$SK_ID_CURR
full[,c('SK_ID_CURR','TARGET')] <- NULL

chr <- full[,sapply(full, is.character)]
num <- full[,sapply(full, is.numeric)]

chr[is.na(chr)] <- "Not Available"

fac <- chr %>% 
  lapply(as.factor) %>% 
  as_data_frame()


full <- bind_cols(fac, num)
rm(chr, fac, num)

full[is.na(full)] <- 0

num <- train[, sapply(train,is.numeric)]

rm(train, test)

train <- full[1:length(Target),]
test <- full[(length(Target)+1):nrow(full),]
```

```{r}
set.seed(123)
inTrain <- createDataPartition(Target, p=.9, list = F)

tr <- train[inTrain,]
va <- train[-inTrain,]

tr_ta <- Target[inTrain]
va_ta <- Target[-inTrain]
```



xgb
```{r}
dtr = xgb.DMatrix(data = data.matrix(tr), label = tr_ta)
dval = xgb.DMatrix(data = data.matrix(va), label = va_ta)
dtrain = xgb.DMatrix(data = data.matrix(rbind(tr,va)), label = c(tr_ta,va_ta))

p <- list(objective = "reg:linear",
          booster = "gbtree",
          eval_metric = "rmse",
          nthread = 4,
          eta = 0.05,
          max_depth = 8,
          min_child_weight = 4,
          gamma = 0.1,
          subsample = 0.9,
          colsample_bytree = 0.5,
          nrounds = 3000)

set.seed(0)
m_xgb <- xgb.train(p, dtr, p$nrounds, list(val = dval), print_every_n = 100, early_stopping_rounds = 100)


test %<>% mutate_if(is.factor, as.integer)
test = xgb.DMatrix(data = data.matrix(test))

pred = predict(m_xgb, test)
pred = ifelse(pred<0,0,pred)
rocgraph(pred)

# data.table::data.table(xgb.importance(model = m_xgb))[1:20,]
# xgb.plot.importance(data.table::data.table(xgb.importance(model = m_xgb))[1:20,])
```

F1 score
```{r}
cutoff_can = seq(0.01, 0.99, by = 0.01)
cutoff_out = t(sapply(1:length(cutoff_can),function(i) cutoff_res(pred, y_test, cutoff_can[i])[[1]]))

colnames(cutoff_out) = c("cutoff","error rate","sensitivity","specificity","f1 score")

cutoff_out[which.max(cutoff_out[,5]),]

cutoff_res(pred, y_test, cutoff_out[which.max(cutoff_out[,5]), 1])[[2]]
```


F1지표 최대화 cut-off(xg-boost)
```{r}
cutoff_res = function(pred_prob, response, cutoff){
  pred = ifelse(pred_prob> cutoff, 1, 0)
  error_rate = mean(response != pred)
  sensitivity = sum(response == 1 & pred == 1)/sum(response == 1)
  specificity = sum(response == 0 & pred == 0)/sum(response == 0)
  precision = sum(response == 1 & pred == 1)/sum(pred == 1)
  recall = sensitivity
  if (sum(response == 1 & pred == 1) == 0) {f1 = 0}
  else {f1 = 2*(precision*recall)/(precision+recall)}
  cross_table = table(response, pred)
  return(list(res = c(cutoff, round(error_rate,4),
  round(sensitivity,4), round(specificity,4), round(f1, 4)),
  cross_table = cross_table))
}
```



ROC CURVE
```{r}
# AUC
library(ROCR)

rocgraph <- function(pred){
  # Training set
  AUC = performance(prediction(pred, y_test) , "auc")
  AUC@y.values # area under the curve
  
  # ROC curve
  ROC = performance(prediction(pred ,y_test) , "tpr","fpr")
  plot(ROC , main = paste("ROC curve for Train data\n AUC:",
  round(as.numeric(AUC@y.values),4)),
  col = "blue", lwd = 2.5)
  abline(c(0,0), c(1,1), lty = 2, lwd = 2)
}
```




logistic regression
```{r}
a = cbind(train, Target)
a$Target = as.factor(a$Target)

fitControl <- trainControl(## 4-fold CV
  method = "cv",
  number = 4,
  savePredictions = TRUE
)

mod_fit <- train(Target ~ .,  data = a[,c(10:118)], method="glm", family=binomial(),
                 trControl=fitControl)

pred = predict(mod_fit, test, type = 'prob')
rocgraph(pred['1'])
```


Regularized Logistic Regression
```{r}
a = cbind(train, Target)
a$Target = as.factor(a$Target)

cctrl1 <- trainControl(method = "cv", number = 3, returnResamp = "all")
                       # classProbs = TRUE,
                       # summaryFunction = twoClassSummary)
rlGrid <- expand.grid( cost = c(200,2,0.02),
                       loss = c("L1", "L2_dual", "L2_primal"),
                       epsilon = c(0.001,0.01) )

test_class_cv_model <- train(Target~., data = a,
                             method = "regLogistic",
                             tuneGrid = rlGrid, 
                             trControl = cctrl1,
                             # metric = "ROC",
                             preProc = c("center", "scale"))

rlr_model = test_class_cv_model


pred = predict(rlr_model, test, type = 'prob')
rocgraph(pred['1'])

sort(abs(rlr_model$finalModel$W))


namesA = names(data.frame(abs(data.frame(rlr_model$finalModel$W))>0.1))[abs(data.frame(rlr_model$finalModel$W))>0.1]

t(as.matrix(data.frame(rlr_model$finalModel$W)[,namesA]))


```


logit bagging(skip)
```{r}
a = cbind(train, Target)
a$Target = as.factor(a$Target)

seeds <- vector(mode = "list", length = nrow(a) + 1)
seeds <- lapply(seeds, function(x) 1:20)

rctrl1 <- trainControl(method = "cv", number = 3, returnResamp = "all", seeds = seeds)
rctrl2 <- trainControl(method = "cv", seeds = seeds)

test_class_cv_form <- train(Target ~ ., data = a, 
                            method = "logicBag", 
                            trControl = rctrl2,
                            tuneGrid = expand.grid(ntrees = 2:3,
                                                   nleaves = 2^(4:5)),
                            B = 3,
                            seed = 1)

pred = predict(test_class_cv_form, test, type = 'prob')
rocgraph(pred['1'])
```


logit bagging
```{r}
pred = list()

for (i in 1:100){
  sample = sample(ncol(a), 10, replace=F)
  
  glm_model = glm(Target~., data = a[,sample], family = "binomial")
  
  pred[[i]] = predict(glm_model, test, type = "response")
}

pred = matrix(unlist(pred), nrow = 30752, ncol = 100)
pred = apply(pred, 1, mean)

rocgraph(pred)
```


logistic boosting
```{r}
require(gbm)

Boston.boost=gbm(Target ~ . ,data = a,distribution = "gaussian", n.trees = 10000,
                  shrinkage = 0.01, interaction.depth = 4)


summary(Boston.boost) #Summary gives a table of Variable Importance and a plot of Variable Importance


#Plot of Response variable with lstat variable
plot(Boston.boost,i="lstat") 
#Inverse relation with lstat variable

plot(Boston.boost,i="rm") 
#as the average number of rooms increases the the price increases

n.trees = seq(from=100 ,to=10000, by=100) #no of trees-a vector of 100 values 

#Generating a Prediction matrix for each Tree
predmatrix<-predict(Boston.boost,test,n.trees = n.trees)
dim(predmatrix) #dimentions of the Prediction Matrix

#Calculating The Mean squared Test Error
test.error<-with(test,apply( (predmatrix-y_test)^2,2,mean))
head(test.error) #contains the Mean squared test error for each of the 100 trees averaged

#Plotting the test error vs number of trees

plot(n.trees , test.error , pch=19,col="blue",xlab="Number of Trees",ylab="Test Error", main = "Perfomance of Boosting on Test Set")

#adding the RandomForests Minimum Error line trained on same data and similar parameters
abline(h = min(test.error),col="red") #test.err is the test error of a Random forest fitted on same data
legend("right",c("Minimum Test error Line for Random Forests"),col="red",lty=1,lwd=1)

rocgraph(data.frame(predmatrix)[,4]-1)
```




