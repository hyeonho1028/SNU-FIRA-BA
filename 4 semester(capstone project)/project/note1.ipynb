{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import def_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(def_save)\n",
    "from def_save import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../../Downloads/clustering_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long beach location\n",
    "df2 = port_5km(df1, 33.754929, -118.214344)\n",
    "df3 = representative_value(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clutering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4 = auto_clustering(df3, 8)\n",
    "df5 = re_cluster(df4, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = pd.merge(df1, df5[['MMSI', 'cluster_prediction']], how='left', on='MMSI').dropna().reset_index(drop=True)\n",
    "# folium_save(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, test data split(Split by : 2018 year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_rep = representative_value(train_data.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cluster = auto_clustering(train_data_rep, 8)\n",
    "train_data_cluster2 = re_cluster(train_data_cluster, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = pd.merge(df1, train_data_cluster2[['MMSI', 'cluster_prediction']], how='left', on='MMSI').dropna().reset_index(drop=True)\n",
    "# folium_save(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good clustering -> baseline selection of train ship -> test ship search route for baseline -> \n",
    "##### Learning with ships having similar route\n",
    "#####  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_rep = representative_value(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = list(set(list(range(0,train_data_rep.shape[1])))-set(list(range(0,train_data_rep.shape[1],3))))\n",
    "idx.extend([train_data_rep.columns.tolist().index('MMSI'), list(range(0,train_data_rep.shape[1],3))[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_rep = train_data_rep.iloc[:, idx].drop(columns=['rpst_value_LAT8', 'rpst_value_LON8', 'rpst_value_LAT9', 'rpst_value_LON9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_rep = pd.merge(train_data_rep, train_data_cluster2[['MMSI', 'cluster_prediction']], how='left', on='MMSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_rep = representative_value(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = list(set(list(range(0,test_data_rep.shape[1])))-set(list(range(0,test_data_rep.shape[1],3))))\n",
    "idx.extend([test_data_rep.columns.tolist().index('MMSI'), list(range(0,test_data_rep.shape[1],3))[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_rep = test_data_rep.iloc[:, idx].drop(columns=['rpst_value_LAT8', 'rpst_value_LON8', 'rpst_value_LAT9', 'rpst_value_LON9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_rep = route_similar(train_data_rep, test_data_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test data 유사 군집 종류와 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001    4\n",
       "100     2\n",
       "72      1\n",
       "Name: cluster_prediction, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(test_data_rep['cluster_prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3001 cluster에 속한 predict ship이 많으므로 3001만 먼저 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = '3001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data_rep[train_data_rep['cluster_prediction']==cluster_name][['MMSI', 'y_value7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data_rep[test_data_rep['cluster_prediction']==cluster_name][['MMSI', 'y_value7']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent variable - Data_metrization\n",
    "###### effect dimensional reduction + baseline's scheduled time for last point \n",
    "######  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_final = Dmetrization(pd.read_csv('../../Downloads/clustering_2.csv'), train) # raw data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = Dmetrization(pd.read_csv('../../Downloads/clustering_2.csv'), test) # raw data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_final = test_receive_t1t7(train_final, test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale, maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = xgb.XGBRegressor(booster='gbtree', \n",
    "                          eta=0.01, \n",
    "                          scale_pos_weight=0.1,\n",
    "                          min_child_weight=13,\n",
    "                          colsample_bylevel=0.3,\n",
    "                          colsample_bytree=0.8,\n",
    "                          subsample=1,\n",
    "                          max_depth=8, \n",
    "                          gamma=0.1, \n",
    "                          alpha=0.1,\n",
    "                          seed=1028,\n",
    "                          n_estimators=1000).fit(\n",
    "    scale(train_final.drop(columns=['y_value'])), train_final['y_value']).predict(scale(test_final.drop(columns=['y_value'])))\n",
    "y_pred = np.round(y_pred, 1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.3</td>\n",
       "      <td>76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.9</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.4</td>\n",
       "      <td>93.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.2</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  true\n",
       "0        84.3  76.8\n",
       "1        83.9  84.9\n",
       "2        88.4  93.8\n",
       "3        84.2  90.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pd.DataFrame({'prediction': y_pred, 'true': test_final['y_value']}), 1).astype(float)\n",
    "# np.mean((np.round(pd.DataFrame({'prediction': y_pred, 'true': test_final['y_value']}), 1).astype(float).iloc[:,1]-np.round(pd.DataFrame({'prediction': y_pred, 'true': test_final['y_value']}), 1).astype(float).iloc[:,0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 10/10 [1:06:00<00:00, 391.12s/it]\n"
     ]
    }
   ],
   "source": [
    "mse = 100\n",
    "new_mse = 0\n",
    "L = []\n",
    "for reg_lambda in tqdm([1/20 for i in list(range(1, 11))]):\n",
    "    for colsample_bylevel in [i/20 for i in list(range(1, 11))]:\n",
    "        for colsample_bytree in [i/20 for i in list(range(1, 11))]:\n",
    "            for subsample in [i/20 for i in list(range(1, 11))]:\n",
    "                for max_delta_step in [i/20 for i in list(range(1, 11))]:\n",
    "                    for min_child_weight in list(range(1, 16)):\n",
    "                        for max_depth in list(range(1, 8)):\n",
    "                            y_pred = xgb.XGBRegressor(booster='gbtree', \n",
    "                                      max_delta_step=max_delta_step,\n",
    "                                      scale_pos_weight = 1,\n",
    "                                      eta=0.01, \n",
    "                                      min_child_weight=min_child_weight,\n",
    "                                      max_depth=max_depth, \n",
    "                                      reg_lambda=reg_lambda,\n",
    "                                      gamma=0.1, \n",
    "                                      alpha=0.1, \n",
    "                                      subsample=subsample,\n",
    "                                      colsample_bylevel = colsample_bylevel,\n",
    "                                      colsample_bytree = colsample_bytree,seed = 1028,\n",
    "                                      n_estimators=1000).fit(\n",
    "                (train_final.drop(columns=['y_value'])), train_final['y_value']).predict((test_final.drop(columns=['y_value'])))\n",
    "                            y_pred = np.round(y_pred, 1).astype(str)\n",
    "                            new_mse = np.mean((np.round(pd.DataFrame({'prediction': y_pred, 'true': test_final['y_value']}), 1).astype(float).iloc[:,1]-np.round(pd.DataFrame({'prediction': y_pred, 'true': test_final['y_value']}), 1).astype(float).iloc[:,0])**2)\n",
    "                    \n",
    "                            if new_mse < mse:\n",
    "                                mse = new_mse\n",
    "                                L = [reg_lambda, colsample_bylevel, colsample_bytree, subsample, max_delta_step, min_child_weight, max_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.47500000000002"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.4, 0.8, 1.0, 1.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(def_save)\n",
    "from def_save import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
