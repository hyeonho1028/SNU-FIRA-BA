---
title: "data based_final"
author: "Hyeonho Lee"
date: "2018년 9월 6일"
output: html_document
---

```{r}
library(ggplot2)
library(dplyr)
library(car)
```


```{r}
dat <- read.csv('C:/workspace/Github/snu_edu/2 semester/DataBased Statistical Decision Model/기말과제/Final/mobility.csv')
```

```{r}
dat
```

1. A map of mobility

a. Make a plot where the x and y coordinates are longitude and latitude, and mobility is indicated
by color (possibly grey scale), by a third coordinate, or some other suitable device.
Make sure your map is legible. Describe the geographic pattern in words. 
[logitude, latitude, mobility 변수의 값을 나타내는 그래프를 그리세요. X 축과 Y 축이 longitude 와 latitude 로 된 그래프를 만들어 Mobility 변수의 값을 색을 이용하거나, 차원을 늘리거나 또는 다른 방법을
이용해서 표시하세요. 그래프는 읽기 편하도록 만들고, 그래프를 통해서 발견된 mobility의 지리적 경향을 말로 설명하세요. ]

```{r}
ggplot(dat, aes(x = Longitude, y = Latitude)) + geom_point(aes(color = Mobility)) + 
  scale_color_gradient(low = "red", high = "black")
```
미국 본토의 중북부, 중부, 중남부 지방에서 출생한 아이가 상위 1분위에 속할 확률이 가장 높음이 보인다.


b. Discretizing the Mobility values may enhance visualizing. Create a new variable, called
MobilityCat with values high if Mobility > 0.1, and low otherwise. Make a plot
where the x and y coordinates are longitude and latitude, and the categorized mobility (i.e.
MobilityCat) is indicated by color. This time, filter your observations so that only the continental
part of USA is visible (that is, remove data corresponding to Alaska and Hawaii). Has
the geographic pattern become clearer? 
[ Mobility 변수의 값을 몇 개의 카테고리로 나누면 그래프의 가독성을 높일 수가 있습니다. MobilityCat이라는 이름의 새 변수를 만드세요. 새 변수의 값은 mobility > 0.1 이면 high, 그렇지 않으면 low 로 주면 됩니다. 새로운 변수의 값이 색으로 표현된 그래프를 새로 만드세요. 이 그래프는 위 문제와 같이 x, y축이 위도와 경도이 되도록 그리면 됩니다. 이번에는 알래스카와 하와이를 제외한 미 대륙 본토만을 표시합니다.
Mobility의 지리적 경향이 더 확실하게 보이나요? ]

```{r}
dat$MobilityCat = dat$Mobility
dat$MobilityCat[dat$MobilityCat>0.1] = 'high'
dat$MobilityCat[dat$MobilityCat<=0.1] = 'low'

dat %>% filter(State != 'HI' & State != 'AK') %>% 
  ggplot(aes(x = Longitude, y = Latitude)) + geom_point(aes(color = MobilityCat))

dat %>% filter(State != 'HI' & State != 'AK' & is.na(MobilityCat) == FALSE) %>% 
  ggplot(aes(x = Longitude, y = Latitude)) + geom_point(aes(color = MobilityCat))
```
위에서 본것과 살짝 다르게 보이는데, 더 정확하게 볼 수 있다. 예를들어 중부, 서부지역이 0.1이상임을 확실하게 볼 수 있고, 동부지방의 경우 실리콘밸리 지역외에는 0.1이하임을 볼 수 있다.


2. A bunch of simple regression models
Make scatter plots of mobility against each of the following variables. Include on each plot a line
for the simple or univariate regression, and give a table of the regression coefficients. Carefully
explain the interpretation of each coefficient. Do any of the results seem odd? 
[ Y축을 Mobility로하는 하면서 다음의 리스트에 있는 변수를 X축의 값으로 하는 그래프를 각각 그리세요. 적합된 회귀선을 각각의 그래프에 추가하며, 적합된 coefficient 의 값을 테이블에 정리하고, 각각의 coefficient를 해석하세요. 적합 결과에 대해 간단히 논하세요. ]

a. Population
b. Mean household income per capita
c. Racial segregation
d. Income share of the top 1%
e. Mean school expenditures per pupil
f. Violent crime rate
g. Fraction of workers with short commutes.
```{r}
dat <- read.csv('C:/workspace/Github/snu_edu/2 semester/DataBased Statistical Decision Model/기말과제/Final/mobility.csv')
```

```{r}
par(mfrow = c(2, 4))
model1 = lm(Mobility~Population, data = dat)
plot(y = dat$Mobility, x = dat$Population, main = 'Population', xlab = 'Population', ylab = 'Mobility')
abline(model1, col = 'red')

model2 = lm(Mobility~Income, data = dat)
plot(y = dat$Mobility, x = dat$Income, main = 'Income', xlab = 'Income', ylab = 'Mobility')
abline(model2, col = 'red')

model3 = lm(Mobility~Seg_racial, data = dat)
plot(y = dat$Mobility, x = dat$Seg_racial, main = 'Seg_racial', xlab = 'Seg_racial', ylab = 'Mobility')
abline(model3, col = 'red')

model4 = lm(Mobility~Share01, data = dat)
plot(y = dat$Mobility, x = dat$Share01, main = 'Share01', xlab = 'Share01', ylab = 'Mobility')
abline(model4, col = 'red')

model5 = lm(Mobility~School_spending, data = dat)
plot(y = dat$Mobility, x = dat$School_spending, main = 'School_spending', xlab = 'School_spending', ylab = 'Mobility')
abline(model5, col = 'red')

model6 = lm(Mobility~Violent_crime, data = dat)
plot(y = dat$Mobility, x = dat$Violent_crime, main = 'Violent_crime', xlab = 'Violent_crime', ylab = 'Mobility')
abline(model6, col = 'red')

model7 = lm(Mobility~Commute, data = dat)
plot(y = dat$Mobility, x = dat$Commute, main = 'Commute', xlab = 'Commute', ylab = 'Mobility')
abline(model7, col = 'red')

rbind(summary(model1)$coef, summary(model2)$coef, summary(model3)$coef, summary(model4)$coef, summary(model5)$coef, summary(model6)$coef, summary(model7)$coef)
```
그래프를 보았을 때, 회귀식이 대부분 잘 적합되어 보이진 않는다. School_spening, Commute, Seg_racial이 그나마 잘 적합된 것 같지만 이도 많이 부족해 보인다. 래버리지도 많이 보이고, 설명력이 많이 떨어져 보인다. 그러나 알 수 있는 부분은 회귀식의 추세를 봄으로써 각각의 변수가 Mobility에 어떤 영향을 미치는 지 알 수 있다. 회귀선이 아래로 내려가는 추세라면, 반비례관를 추정할 있고, 회귀선이 위로 올라가는 추세라면 비례관계를 추정할 수 있다. 
수치적으로 coefficient를 보면 Population, Seg_racial, Share01, Violent_crime는 한 단위 증가할 때, Mobility를 감소시키고, Income, School_spending, Commute는 한 단위 증가할 때, Mobility를 증가시키는 점을 알 수 있다. 즉 Mobility를 증가시키기 위해선 Income, School_spending, Commute가 높아야 됨을 알 수 있다.


3. All things considered
Run a linear regression of mobility against all appropriate covariates. 
[ 적절한 설명변수들을 이용하여 다중회귀분석을 실시합니다. ]

a. Report all regression coefficients and their standard errors; you may use either a table or a
figure as you prefer. 
[ 적합된 계수의 값과 그 standard error를 보여주세요. ]
```{r}
model = lm(Mobility~., data = dat[,-c(1:2)])
coef_1 = summary(model)$coef
coef_1
```
Id, Name 변수는 Mobility와 인과관계가 전혀 없으므 제거한 후 모든 변수를 사용하여 모델을 적합하였다. 어떤 변수가 Mobility를 감소시키고, 증가시키는지 확인 할 수 있다.




b. Explain why the ID variable must be excluded. 
[ Variable ID는 설명변수로 쓰이지 않습니다. 이유를 설명하세요. ]


Mobility와의 인과관계가 전혀 없기 때문이다. Id나 Name에 따라서 Mobility가 변화한다는 것은 전혀 관계가 없다.



c. Explain which other variables, if any, you excluded from the regression, and why. (If you
think they can all be used, explain why.) [For this question, do not use any automated
variable selection, and try to keep as many variables as possible.] 
[ 다른 설명변수 중에 모형 적합에 쓰지 않은 변수가 있다면, 왜 제외했는지 설명하세요. 만약 모두 쓰였다면, 그렇게 할 수 있는 이유를 설명하세요. ]
```{r}
names(summary(model)$coef[,4][summary(model)$coef[,4] < 0.05])
```
p value가 0.05이하인 값들의 변수명

```{r}
model = lm(Mobility~., data = dat %>% select(State, Black, Seg_racial, Seg_poverty, 
                                             Commute, Mobility,Middle_class, Manufacturing, 
                                             Migration_out, Foreign_born, Social_capital, Single_mothers))
coef_2 = summary(model)$coef
```
p value가 0.05이상인 경우 Mobility에 대한 계수의 추정이 유의미하지 않다고 판단하였기 때문에 제거하였다.


d. Compare the coefficients you found in problem 2 to the coefficients for the same variables in
this regression. Are they significantly different? Have any changed sign? 
[ 2 번 문제의 답과 다중회귀 분석에서 적합한 coefficient 들을 비교하세요. 다른 값들이 나왔나요? 계수의 부호가 바뀌었나요? ]
```{r}
coef_1[,1, drop = F]
coef_2[,1, drop = F]
```
계수의 값과 부호가 바뀌었음을 볼 수 있다. 회귀분석에 사용된 변수들이 바뀌면서, 공분산이 사라지므로 변수의 계수에 영향을 미친다.


e. Take a look at the variation inflation factor for each variable. Report those variables with
VIF greater than 10. Do you suspect a (nearly) multicollinearity? If so, give a reason for, and
suggest a way to avoid it. 
[ Variation inflation factor (VIF) 를 보고, VIF 가 10 보다 큰 변수들을 찾으세요. Multicollinearity가 있다고 의심이 되나요? 그렇다면, 이유를 대고, multicollinearity를 피할 수 있는 방법을 제시하세요. ]
```{r}
library(car)
library(dplyr)
model = lm(Mobility~., data = dat %>% select(State, Black, Seg_racial, Seg_poverty, 
                                             Commute, Mobility,Middle_class, Manufacturing, 
                                             Migration_out, Foreign_born, Social_capital, Single_mothers))
vif(model)

```
State가 매우 높은 vif를 보이고 있다. 통상적으로 10이상일 때, 다중공선성이 존재한다고 하는데 State가 너무 높으므로 다중공선성이 의심이 됩니다. multicollinearity를 피하기 위해서 변수를 제거하는 방법을 택합니다. 또다른 방법은 주성분 분석 등을 사용하는 방법이 있지만, 여기선 변수제거를 선택했습니다.


```{r}
model = lm(Mobility~., data = dat %>% select(Black, Seg_racial, Seg_poverty, Commute, 
                                             Mobility,Middle_class, Manufacturing, Migration_out, 
                                             Foreign_born, Social_capital, Single_mothers))
vif(model)
```
State를 제거한 후의 회귀분석은 vif가 사라진것을 확인 할 수 있습니다.(VIF>10이 다중공선성에 대한 의심 조건)



4. Please in my front yard
a. Inspect the missingness pattern in variables Colleges, Tuition and Graduation. [Note:
NA is a missing value.] How many observations have no measurements for these variables?
[ 변수 Colleges, Tuition and Graduation에는 기록되지 않은 값(missing value)가 많이 있습니다. 얼마나 많은 관측값에서 이 변수들의 값이 기록되지 않았나요? ]

```{r}
dat <- read.csv('C:/workspace/Github/snu_edu/2 semester/DataBased Statistical Decision Model/기말과제/Final/mobility.csv')
```

```{r}
sum(is.na(dat[,'Colleges']))
sum(is.na(dat[,'Tuition']))
sum(is.na(dat[,'Graduation']))
```

b. Did the missing values happen at random? To answer this, plot a scatter of Mobility and
Population (choose a suitable scale for Population), and inspect which data points have
missing values in (all of, or some of) variables Colleges, Tuition and Graduation. 
[누락된 값이 임의로 형성되었나요? 대답을 하기 위해서, Mobility와 Population의 scatter plot을 그리고, 어떤 관측값에서 전술한 세 변수의 값이 누락되었는지 조사하세요. ]
```{r}
library(ggplot2)
ggplot(dat, aes(x = log(Population), y = Mobility)) + geom_point(aes(color = is.na(Colleges)))
ggplot(dat, aes(x = log(Population), y = Mobility)) + geom_point(aes(color = is.na(Tuition)))
ggplot(dat, aes(x = log(Population), y = Mobility)) + geom_point(aes(color = is.na(Graduation)))
```

c. Create a new variable, called HE, whose value is TRUE if there is a higher education institution
in the community, is FALSE if not. Replace all NA values in variables Colleges, Tuition
and Graduation with 0. [ HE 라는 이름의 새 변수를 만드세요. 각 community (관측값) 에 고등 교육기관이 있다면 HE 의 값은 TRUE, 그렇지 않다면 FALSE로 줍니다. 전술한 세 변수의 NA 값은 모두 0 으로 바꿉니다. ]
```{r}
dat['Colleges'][is.na(dat['Colleges'])] = 0
dat['Tuition'][is.na(dat['Tuition'])] = 0
dat['Graduation'][is.na(dat['Graduation'])] = 0

dat$HE = NA
dat$HE[dat$Colleges > 0 | dat$Tuition > 0 | dat$Graduation > 0] = T
dat$HE[is.na(dat$HE)] = F

table(dat$HE)
```



5. All things considered, again.
Fit a linear regression model, incorporating your findings in problems 3 and 4. If you have removed,
created, or modified variables, explain. Report all regression coefficients and their standard errors.
Use this model for all problems below. 
[3번과 4번 문제의 답을 포함하여 새로운 다중 회귀 분석모형을 세우고, 적합합니다. 새로운 변수를 만들거나, 어떤 변수를 지웠다면, 설명하세요. 모든 coefficient의 값과 그 standard error를 보여주세요. 아래의 문제에는 이 모형을 이용합니다. ]
```{r}
model = lm(Mobility ~ Black + Seg_racial + Seg_poverty + Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Social_capital + Single_mothers + HE + 
             Colleges + Tuition + Graduation, data = dat)
summary(model)$coef
```
3번에서 VIF가 높았던 State를 제거하고, 4번에서 언급한 고등교육현황과 새로 만든 컬럼인 HE를 사용한 회귀분석을 실시하였다.


```{r}
model = lm(Mobility ~ Black + Seg_racial + Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE, data = dat)
summary(model)
```
p-value가 0.2보다 낮은 변수들은 Mobility에 대한 계수의 추정이 유의미하지 않다고 판단하였기 때문에 제거하였다.


6. Make a map of predicted mobility.
Make a map of the model’s predicted mobility. How does it compare, qualitatively, to the map
of actual mobility? 
[5번의 모형을 이용하여 예측한 mobility를 ( 1번과 같이 ) 지도 위에 표시합니다. 실제 관측값의 지도와 비교하세요. ]
```{r}
model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE, data = dat)
pred = predict(model, newdata = dat)

pred = cbind(pred, dat)

par(mfrow = c(2, 2))

pred$predCat = pred$pred
pred$predCat[pred$predCat>0.1] = 'high'
pred$predCat[pred$predCat<=0.1] = 'low'
pred %>% filter(is.na(predCat) == FALSE) %>% 
  ggplot(aes(x = Longitude, y = Latitude)) + geom_point(aes(color = predCat))

dat$MobilityCat = dat$Mobility
dat$MobilityCat[dat$MobilityCat>0.1] = 'high'
dat$MobilityCat[dat$MobilityCat<=0.1] = 'low'

dat %>% filter(is.na(MobilityCat) == FALSE) %>% 
  ggplot(aes(x = Longitude, y = Latitude)) + geom_point(aes(color = MobilityCat))
```
NA값을 제거하고 본 결과이다. 굉장히 비슷함을 볼 수 있고, 예측을 잘 했다고 생각된다.




7. Just because I was there
Find Pittsburgh in the data set. For this question, assume that the model (you have fitted just
before) is well-fitted.
a. What its actual mobility? What is its predicted mobility, according to the model?
```{r}
ggplot(dat, aes(pred$pred, pred$Mobility, xlab = 'predict', ylab = 'Mobility')) + 
  geom_point() + geom_smooth()
```

b. Holding all else fixed, what is the predicted mobility if the violent crime rate is doubled? If it is halved?
```{r}
model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE+Violent_crime, data = dat)
pred1 = predict(model, newdata = dat)

model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE+I(2*Violent_crime), data = dat)
pred2 = predict(model, newdata = dat)

model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE+I(Violent_crime/2), data = dat)
pred3 = predict(model, newdata = dat)

pred = data.frame(cbind(dat$Mobility, pred1, pred2, pred3))
colnames(pred) = c('a', 'b', 'c', 'd')

require('gridExtra')

theme_set(theme_bw())
p1 = pred %>% ggplot(aes(pred$a, pred$b)) + geom_point() + xlab('Mobility') + ylab('predict')
p2 = pred %>% ggplot(aes(pred$a, pred$c)) + geom_point() + xlab('Mobility') + ylab('2*Violent_crime predict')
p3 = pred %>% ggplot(aes(pred$a, pred$d)) + geom_point() + xlab('Mobility') + ylab('Violent_crime/2 predict')

grid.arrange(p1, p2, p3, ncol=2)
```

c. Provide a 95% confidence interval for the expected mobility at Pittsburgh.
```{r}
model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE, data = dat)
pred = predict(model, newdata = dat, interval='confidence')


pred = cbind(pred, dat)
pred[pred$Name == 'Pittsburgh',][1:3]
```




d. Provide a 95% prediction interval for the expected mobility at Pittsburgh. Explain the difference.
```{r}
model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE, data = dat)
pred = predict(model, newdata = dat, interval='prediction')

pred = cbind(pred, dat)
pred[pred$Name == 'Pittsburgh',][1:3]
```



8. After making proper allowances
a. Make a map of the model’s residuals. [5번의 모형에서 나온 잔차를 지도 위에 표시하세요. ]
```{r}
model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers + HE, data = dat)

pred = predict(model, newdata = dat)

dat_resi = mutate(dat, dat$Mobility - pred)
colnames(dat_resi)[46] = 'residuals'
dat_resi %>% filter(is.na(residuals) == F) %>% 
  ggplot(aes(x = Longitude, y = Latitude)) + geom_point(aes(color = residuals))

```




b. What are the five communities with the largest positive residuals? The five with the most
negative residuals? Provide the names of the communies. (Can you mark these on the map?)
[ 잔차가 ( 양으로, 그리고 음으로) 가장 큰 다섯 개의 관측값의 이름을 찾으세요. ( 지도 위에 표시할 수 있나요? ) ]
```{r}
dat_resi_head = dat_resi %>% arrange(desc(residuals)) %>% head(5)
dat_resi_tail = dat_resi %>% arrange(desc(residuals)) %>% tail(5)

dat_resi$head = NA
dat_resi$head[dat_resi$ID %in% dat_resi_head$ID] = 'positive top5'
dat_resi$head[dat_resi$ID %in% dat_resi_tail$ID] = 'negative top5'
dat_resi$head[is.na(dat_resi$head) == T] = 'not top5'

dat_resi %>% ggplot(aes(x = Longitude, y = Latitude)) + geom_point(aes(col = head))


```


9. Expectations and reality
a. Make a scatterplot of actual mobility against predicted mobility. Is the relationship linear?
Should it be, is the model right? Is the relationship flat? Should it be, is the model right? 
[ 실제 mobility의 값과 예측된 mobility의 값을 이용하여 scatter plot을 그리세요. 관계가 선형인가요? 그렇다면, 좋은 모형인가요? 서로 관계가 없나요? 그렇다면, 좋은 모형인가요? ]
```{r}
model = lm(Mobility ~ Black +  Commute + Middle_class + Manufacturing + 
             Migration_out + Foreign_born + Single_mothers, data = dat)
pred = predict(model, newdata = dat)


dat_pred = cbind(dat, pred)
dat_pred %>% ggplot(aes(Mobility, pred)) + geom_point() + geom_smooth()
# 관계는 선형으로 보인다. 좋은 모형은 아닌것 같다. 서로 관계는 있다. (증가추세, 안좋은 모형이라구)
```
관계는 선형보다 비선형에 가깝게 보인다. 그러나 모델이 관계를 잘 표현해서 적합은 잘 되었다고 판단한다.



b. Make a scatterplot of the model’s residuals against predicted mobility. Is the relationship
linear? Should it be, is the model right? Is the relationship flat? Should it be, is the model right? 
[ 모형의 잔차와 예측된 mobility의 값을 이용하여 scatter plot을 그리세요. 관계가 선형인가요? 그렇다면, 좋은 모형인가요? 서로 관계가 없나요? 그렇다면, 좋은 모형인가요?]
```{r}
dat_resi = mutate(dat, dat$Mobility - pred)
dat_resi = cbind(dat_resi, pred)
colnames(dat_resi)[46:47] = c('residuals', 'predict')


dat_resi %>% ggplot(aes(predict, residuals)) + geom_point() + geom_smooth()
# 좋은 모형인것 같다. 나름의 등분산을 유지하고 있다. 선형이다. 관계가 있어보인다. 좋은모형인지는 모르겠다.
```
전체적으로 선형관계는 보이지 않는다. 그러나 predict가 0.1 이후로 등분산성을 위배하므로 선형회귀의 가정이 깨지는 것을 볼 수 있다.



10. Cross-validation, bootstrap and smoothing
For this question, focus on predicting mobility by the fraction of middle class in the community.
[이 문제에서는 각 동네의 중산층의 비율을 이용하여 측합니다. ]
mobility를 예
a. Fit a simple linear regression model y = 0+1x+ϵ to predict Mobility by Middle_class.
Create a plot showing the data points, the fitted regression line, and 95% confidence and
prediction intervals. For the intervals, assume that the error ϵ is i.i.d. N(0, 2). (Is the
assumption right?) 
[ 간단한 회귀분석 모형을 적합하고, 결과를 그림으로 그리세요. 그래프에는 자료의 값, 적합된 회귀분석 모형, 95% confidence and prediction intervals 을 보여줍니다. Interval을 계산하기 위하여, noise의 분포가 i.i.d. N(0, .2) 이라고 가정합니다.( 이 가정이 이 데이타에 잘 맞나요? ) ]
```{r}
dat <- read.csv('C:/workspace/Github/snu_edu/2 semester/DataBased Statistical Decision Model/기말과제/Final/mobility.csv')

model = lm(Mobility ~ Middle_class, data = dat)
pred_con = predict(model, newdata = data.frame(Middle_class = dat$Middle_class), interval = 'confidence')
pred_pre = predict(model, newdata = data.frame(Middle_class = dat$Middle_class), interval = 'prediction')

plot(Mobility ~ Middle_class, data = dat, pch = 16, cex = 0.5)
lines(dat$Middle_class, pred_con[,"lwr"], lty="dashed", col="blue")
lines(dat$Middle_class, pred_con[,"upr"], lty="dashed", col="blue")
lines(dat$Middle_class, pred_pre[,"lwr"], col="red")
lines(dat$Middle_class, pred_pre[,"upr"], col="red")

# 이건 나중에 해석 토요일에 보고서 완성하면서
```

b. Use a resampling method to obtain 95% confidence interval. Can you build a 95% prediction
interval?
( resampling 방법을 이용하여 95% confidence interval을 계산합니다. 95% prediction interval 도 resampling method 를 이용하여 계산할 수 있나요? )
```{r}
library(dplyr)
dat_boot <- list()

for(i in 1:500){
  dat_boot[[i]] <- dat %>% 
    sample_n(size = 100) %>%
    summarise(median_mobility = median(Mobility, na.rm = T), median_class = median(Middle_class, na.rm = T))
}

dat_boot = bind_rows(dat_boot)
model = lm(median_mobility ~ median_class, data = dat_boot)
pred_con = predict(model, newdata = data.frame(median_class = dat_boot$median_class), interval = 'confidence')
pred_pre = predict(model, newdata = data.frame(median_class = dat_boot$median_class), interval = 'prediction')

plot(median_mobility ~ median_class, data = dat_boot, pch = 16, cex = 0.5)
lines(dat_boot$median_class, pred_con[,"lwr"], lty="dashed", col="blue")
lines(dat_boot$median_class, pred_con[,"upr"], lty="dashed", col="blue")
lines(dat_boot$median_class, pred_pre[,"lwr"], col="red")
lines(dat_boot$median_class, pred_pre[,"upr"], col="red")
```

c. Use a smoothing spline to do a nonparametric regression of Mobility on Middle_class.
Use cross-validation to choose the degree of flexibility. Then use a resampling method to
obtain 95% confidence interval. Create a plot showing the data points, the spline and the
confidence interval. 
[ Smoothing spline을 이용하여 비모수적 회귀분석을 합니다. crossvalidation을 이용하여 smoothing 의 정도를 정하고, resampling 방법을 이용하여 95% confidence interval을 구합니다. 문제 a 와 마찬가지로 그래프를 이용하여 자료, smoothing spline와 그 confidence interval을 모두 표시합니다. ]
```{r}
library(caret)
library(mgcv)
dat2 = na.omit(dat[,c('Middle_class','Mobility')])

model <- gam(Mobility~s(Middle_class), data = dat2)

plot(model, se = TRUE, col = 'red')
with(dat2, points(Middle_class, Mobility-mean(Mobility)))



model <- smooth.spline(x=dat2$Middle_class, y=dat2$Mobility, cv = TRUE)


res <- (model$yin - model$y)/(1-model$lev)      # jackknife residuals
sigma <- sqrt(var(res))                     # estimate sd

upper <- model$y + 2.0*sigma*sqrt(model$lev)   # upper 95% conf. band
lower <- model$y - 2.0*sigma*sqrt(model$lev)   # lower 95% conf. band
matplot(model$x, cbind(upper, model$y, lower), type="l", pch=".", col = 'red')
with(dat2, points(Middle_class, Mobility))


res <- (model$yin - model$y)/(1-model$lev)      # jackknife residuals
sigma <- sqrt(var(res))                     # estimate sd

upper <- model$y + 2.0*sd(dat_boot_df$median)   # upper 95% conf. band
lower <- model$y - 2.0*sd(dat_boot_df$median)   # lower 95% conf. band
matplot(model$x, cbind(upper, model$y, lower), type="l", pch=".", col = 'red')
with(dat2, points(Middle_class, Mobility))






dat_boot <- list()
for(i in 1:500){
  dat_boot[[i]] <- dat2 %>% 
    sample_n(size = 100) %>%
    summarise(median = median(Mobility))
}

dat_boot_df <- bind_rows(dat_boot)
library(mdsr)
library(dplyr)
favstats( ~ median, data = dat_boot_df)



pred_con_lwr = pred - 1.96 * sd(dat_boot_df$median)/sqrt(500)
pred_con_upr = pred + 1.96 * sd(dat_boot_df$median)/sqrt(500)
```

```{r}
model <- smooth.spline(x=dat2$Middle_class, y=dat2$Mobility, cv = TRUE)
pred <- predict(model, x = dat2$Middle_class)

pred = data.frame(pred$y)

dat_boot <- list()
for(i in 1:500){
  dat_boot[[i]] <- pred %>% 
    sample_n(size = 100) %>%
    summarise(median = median(pred.y))
}

dat_boot_df <- bind_rows(dat_boot)
library(mdsr)
favstats( ~ median, data = dat_boot_df)

pred_con_lwr = pred - 1.96 * sd(dat_boot_df$median)/sqrt(500)
pred_con_upr = pred + 1.96 * sd(dat_boot_df$median)/sqrt(500)


plot(Mobility ~ Middle_class, data = dat2, pch = 16, cex = 0.5)
lines(model, col = 'red')
lines(dat2$Middle_class, pred_con_lwr[,"pred.y"], col = 'blue', lty="dashed")
lines(dat2$Middle_class, pred_con_upr[,"pred.y"], col = 'blue', lty="dashed")
```


d. Test whether smoothing is needed here. 
[ Smoothing이 필요한지 가설 검정을 하세요. ]
```{r}




```





























